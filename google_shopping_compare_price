from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException
from bs4 import BeautifulSoup
import requests
import json

driver = webdriver.Chrome('C:\\Program Files (x86)\\Google\\chromedriver.exe')
text_search = 'viewsonic x10-4ke'
base_site = 'https://shopping.google.com'
headerss = {  # <-- so the Google will treat your script as a "real" user browser.
    "User-Agent":
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582"
}

driver.get(base_site)
if 'google' in base_site:
    driver.find_element_by_xpath('//*[@id="REsRA"]').send_keys(text_search)
    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="kO001e"]/c-wiz/form/div[2]/div[2]/ul/li[1]/div/div[1]'))).click()
    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="rso"]/div[2]/div[1]/div[3]/div/'
                                                                          'div[2]/div/div/div/div/div[1]/div[2]/div[4]/a'))).click()
    new_url = driver.current_url
    response = requests.get(new_url, headers=headerss).text
    soup = BeautifulSoup(response, 'lxml')
    data = []
    for container in soup.findAll('tr', class_='sh-osd__offer-row'):
      total_price = container.find('div', class_='drzWO').text
      price = container.find('span', class_='g9WBQb fObmGc').text
      supplier = container.find('a', class_='b5ycib shntl').text
      data.append({
        "Title": total_price,
        "Price": price,
        "Supplier": supplier,
      })
    print(json.dumps(data, indent = 2, ensure_ascii = False))

