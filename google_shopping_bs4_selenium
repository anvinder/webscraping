from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException
from bs4 import BeautifulSoup
import requests
import json

driver = webdriver.Chrome('C:\\Program Files (x86)\\Google\\chromedriver.exe')
text_search = 'meural canvas II'
base_site = 'https://shopping.google.com'
headerss = {  # <-- so the Google will treat your script as a "real" user browser.
    "User-Agent":
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari"
    "/537.36 Edge/18.19582"
}

driver.get(base_site)
if 'google' in base_site:
    driver.find_element_by_xpath('//*[@id="REsRA"]').send_keys(text_search)
    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="kO001e"]/c-wiz/form/div[2]/div[2]/'
                                                                          'ul/li[1]/div/div[1]'))).click()
    new_url = driver.current_url
    response = requests.get(new_url, headers=headerss).text
    soup = BeautifulSoup(response, 'lxml')
    data = []
    try:
        for container in soup.findAll(True, {'class': ['sh-dlr__content xal5Id', 'sh-dgr__gr-auto sh-dgr__grid-result', 'sh-dlr__list-result']}):
            if container.find('h3'):
                title = container.find('h3').text
            else:
                title = container.find('h4').text
            price = container.find('span', class_='a8Pemb').text
            supplier = container.find(['div', 'span'], {'class': ['b07ME mqQL1e', 'aULzUe IuHnof']}).text
            data.append({
              "Title": title,
              "Price": price,
              "Supplier": supplier,
            })
    except Exception as e:
        print(e)
    print(json.dumps(data, indent=2, ensure_ascii=False))
